{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用word2vec进行文本情感分类\n",
    "\n",
    "word2vec是Google在2013年开源的一个工具，核心思想是将单词映射为对应的实数向量。\n",
    "\n",
    "word2vec采用的模型有以下两种：\n",
    "\n",
    "1.CBOW(Continuous Bag-Of-Words，即连续词袋模型)在给定上下文单词的情况下，预测目标单词（中心单词）。\n",
    "![https://d2l.ai/_images/cbow.svg](https://d2l.ai/_images/cbow.svg)\n",
    "2.Skip-Gram\n",
    "Skip-Gram算法就是在给出目标单词（中心单词）的情况下，预测它的上下文单词。\n",
    "![https://d2l.ai/_images/skip-gram.svg](https://d2l.ai/_images/skip-gram.svg)\n",
    "\n",
    "经过模型的训练，最终获得每个单词的**词向量**。\n",
    "\n",
    "我们暂不涉及word2vec的训练，而是直接采用预训练的词向量完成我们的任务。\n",
    "\n",
    "预训练中文词向量：https://github.com/Embedding/Chinese-Word-Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安装必要自然语言处理库gensim："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用gensim导入预训练的词向量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(\"sgns.merge.word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用词向量我们可以看到单词之间一些有趣的关系："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"苹果\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"网球\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"多云\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$最大 - 大 = 最小 - 小$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"最大\",\"小\"],negative=[\"大\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$中国 - 北京 = 法国 - 巴黎$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"中国\",\"巴黎\"],negative=[\"法国\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对词向量进行降维，看看不同分类的词在空间上能否隔开："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"147种水果的名字.txt\",errors='ignore') as f:\n",
    "    fruit_words = f.read().split()\n",
    "with open(\"天气学专有词汇.txt\",errors='ignore') as f:\n",
    "    weather_words = f.read().split()\n",
    "with open(\"运动、休闲词库.txt\",errors='ignore') as f:\n",
    "    sports_words = f.read().split()\n",
    "fruit_vecs = np.concatenate([model[fw].reshape((1,300)) for fw in fruit_words if fw in model])\n",
    "\n",
    "weather_vecs = np.concatenate([model[ww].reshape((1,300)) for ww in weather_words if ww in model])\n",
    "sports_vecs = np.concatenate([model[sw].reshape((1,300)) for sw in sports_words if sw in model])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = TSNE(2)\n",
    "reduced_vecs = ts.fit_transform(np.concatenate((fruit_vecs,weather_vecs,sports_vecs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(reduced_vecs)):\n",
    "    if i < len(fruit_vecs):\n",
    "        color = 'b'\n",
    "    elif i>=len(fruit_vecs) and i<(len(fruit_vecs)+len(weather_vecs)):\n",
    "        color = 'r'\n",
    "    else:\n",
    "        color = \"g\"\n",
    "    plt.plot(reduced_vecs[i,0],reduced_vecs[i,1],marker='o',color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编写辅助函数，用于将文本文件转换成字符串："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file2str(file):\n",
    "    with open(file,encoding='gbk',errors='ignore') as f:\n",
    "        s = f.read().replace(\" \",\"\").replace(\"\\n\",\"\")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编写将整个字符串转换为向量的函数，我们假设整个文本的向量就是所有词语向量的均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2vec(s):\n",
    "    import jieba\n",
    "    import numpy as np\n",
    "    cut_s = jieba.cut(s)\n",
    "    vecs = [model[word] for word in cut_s if word in model]\n",
    "    return sum(np.array(vecs))/len(vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入上一讲的所有文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pos = [os.path.join(\"pos\",p) for p in os.listdir(\"pos\")]\n",
    "neg = [os.path.join(\"neg\",p) for p in os.listdir(\"neg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sentences = [file2str(f) for f in pos]\n",
    "neg_sentences = [file2str(f) for f in neg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将所有文本转换为向量，并合并成一个矩阵，用于接下去的机器学习算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_vecs = np.array([str2vec(s) for s in pos_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_vecs = np.array([str2vec(s) for s in neg_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vecs = np.vstack((pos_vecs,neg_vecs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立标注向量，正向文本标注为1，负向文本标注为0："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate((np.ones(len(pos_vecs)), np.zeros(len(neg_vecs))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用逻辑回归（Logistic Regression）进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(Vecs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(Vecs,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入交叉验证："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vecs_train, Vecs_test, labels_train, labels_test = train_test_split(Vecs,labels,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(Vecs_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(Vecs_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于支持向量机（SVM）的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C = 2, probability = True)\n",
    "clf.fit(Vecs_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(Vecs_test,labels_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
